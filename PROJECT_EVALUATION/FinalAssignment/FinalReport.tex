\documentclass[11pt]{article}
\title{\textbf{MSWL Project Evaluation: OpenNebula Project Analysis}}
\author{Sergio Arroutbi Braojos}
\date{\today}

\usepackage{hyperref}
\usepackage[bottom=14em]{geometry}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{cite}
\usepackage{varioref}
\usepackage{placeins}
\usepackage{float}
\usepackage{graphicx}

\restylefloat{table}

\begin{document}

\hypersetup
{   
pdfborder={0 0 0}
}
   
\maketitle

\tableofcontents

\pagebreak

\section{Executive Summary}
This paper tries to perform an estimation of quality for a particular Cloud Computing Open Source Project, in this case, OpenNebula. Apart from that, a comparison of this project to other similar projects which are its competitors, such as CloudStack, Eucalyptus and OpenStack, is performed, considering the same quality model and how these projects score on it.\\
\\
In particular, by means of using a role play, the selection of a Cloud Computing System by a company offering cloud computing, storage and network services for other companies, from the perspective of a member of the Board of Directors of the company.\\
\\
By means of definition of a custom quality model, focused on the necessities of an invented role, OpenNebula project is analyzed, scored, and compared to the other projects. The final aim of this document is to take a decission of which is the best alternative to use, taking into account the most important factors in terms of quality that a Cloud Computing System must have for the invented role.

\section{Introduction} \label{sec:introduction}
This document is an approach to demonstrate the different issues and evaluations that can be taken into consideration in order to make a decission on the selection of an Open Source Project. A complete analysis of the quality of a particular project, in this case, OpenNebula, will be performed, by applying a self-defined quality model. 

\subsection{Document Objectives}
Apart from previously approach, a comparison with the score of other projects into the same quality model will be performed, so that decission making will be structured by following next steps:

\begin{itemize}\itemsep0pt
\item{Defining a role that justifies why some aspects are more or less important from a quality perspective, hence which factors are more valuable to consider in a quality model, in such way that allows to select or discard a particular project.}
\item{Defining a quality model that has been initially agreed and drafted between different students, that allows to obtain a quality score so that comparison between other Cloud Computing Open Source Projects can be performed.}
\item{Defining the different values in terms of scoring (weights) that all of the statements included in the quality model have, according to the role selected.}
\item{Analysing a particular Cloud Computing Open Source Project, OpenNebula in this case, by obtaining metrics of it and sharing with the rest of the students.}
\item{Calculating the final scoring of this particular project, OpenNebula, according to the weights decided according to the role.}
\item{And finally, by comparing the final score to the rest of the projects and justifying the selection of the "Winner Project".}
\end{itemize}

\subsection{Document Structure}
This document follows next structure, in order to accomplish the different phases that must be considered before making the final decission on the Cloud Computing Open Source Project selected:

\begin{itemize}\itemsep0pt
\item{\textbf{Introduction}}. This chapter describes the final aim of this document, how it is structured and the role being taken in order to take into consideration the most important factors to make the final decission on the Cloud Computing Open Source Project.
\item{\textbf{Methodology}}. On this chapter, the Quality Model will be described, justifying the selection of the different attributes to consider, the metrics derived from them and the weights applied taking into consideration the role selected.
\item{\textbf{Analysis}}. Analysis chapter will justify the application of the model, which tools will be used in order to obtain and analyze the different representative metrics and the data sources used to retrieve them. A Goal-Question-Metric (GQM) model will be implemented to describe how OpenNebula project will be analysed.
\item{\textbf{Results}}. Chapter whose final aim is to calculate OpenNebula score obtained by the application of the Quality Model by using the different tools and source data, all of them described on the previous sources.
\item{\textbf{Conclussion}}. In parallel to this document, and analysis of other Cloud Computing Open Source Projects have been performed with the same quality model. However, on those documents the particular weights applied are related to what the other students invented roles have considered to be appropriate. In this and those documents the metrics obtained will be shared.
This document will perform the score of the rest of the projects, taking into account the same weights that this document have taken into consideration. With OpenNebula and the other Cloud Computing Open Source Projects score, the final decission will be taken.

\item{\textbf{Bibliography and References}}. This chapter collects the references and bibliography followed to perform this analysis.

\subsection{Introduction to the Quality Model}
This document considers a Quality Model agreed between some students and a professor in order to have a common starting point. In section~\nameref{sec:methodology} a complete description of the Quality Model will be performed. However, an introduction to it is appropriate to later justify the most important Quality Model Attributes that the role will consider.\\
\\
The Quality Model Main Attributes agreed are described below:
\begin{enumerate}\itemsep0pt
\item{\textbf{Efficiency}}. From the perspective of performance of the software. E.g: Do benchmarks of the product exist? 
\item{\textbf{Documentation}}. Quality of documentation of the project. E.g: Is the project documentation updated frequently?
\item{\textbf{Functionality}}. Quality of the project in terms of representative functionality. E.g: Does this project have a web browser to configure and administrate the resources under control?
\item{\textbf{Professional Support}}. Amount of companies providing professional support. E.g: How many companies provide professional support?
\item{\textbf{Community}}. Community Health as a way of measuring quality. E.g: Has the number of committers grown or decreased in the last year?
\end{enumerate}

With previous quality attributes brought up, now an invention of the role, a description of it and a cathegorization of the most important attributes from her/his perspective can be performed.

\subsection{Role Description}
This document assumes a role play that allows to determine the more important factors from a quality perspective. In particular, the role of a member of the Board of Directors have been considered. So, the main question to answer is next one: \textbf{Which are the more relevant factors for this role?}\\
\\
To answer this question, a first assumption of the personal background of this role must be performed. This member has been part of the leadership group of an important Open Source project.\\
\\
For this reason, his personal and professional background makes him aware of the \textbf{Importance of the Community} for an Open Source Project to succeed along the time.\\
\\
Apart from being aware of the Community, this role considers that \textbf{Documentation} is as well an important factor, as it helps to strengthen and consolidate Community itself.\\
\\
Meanwhile, role's professional background and experience also makes him/her to be aware of the \textbf{Importance of having professional support}.\\
\\
Last, but not least, the board member considers that \textbf{having a full featured functionality and good efficiency/performance is not as important as the previous factors}, as having a strong community and a good professional support can help on improving both attributes in a relatively short period of time.
\end{itemize}

\section{Methodology} \label{sec:methodology}
In order to calculate what is the quality of a project, first of all the Quality Model must be defined. It is not the objective of this chapter to describe on a very detailed basis the different Software Quality Models and its characteristics. However, a very brief description and classification of them is required in order to evaluate them and select the most appropriate, or, as well, the one that can inspire the Final Quality Model.\\
\\
There are many different type of Quality Models to evaluate Software Quality. Several classifications can be taken into consideration:

\subsection{Software Generic Quality Models}
There are Quality Models that have been designed to measure the Quality of the Software, or, at least, the process that is followed to produce software. Examples of this kind of Quality Models are:
\begin{itemize}\itemsep0pt
\item{ISO 9126}~\cite{ISO00, ISO01}.
This model defines a set of six super-attributes that are considered the more relevant from Software Quality perspective:
\begin{enumerate}
\item{Functionality}
\item{Reliability}
\item{Usability}
\item{Efficiency}
\item{Maintainability}
\item{Portability}
\end{enumerate}
Each of the super-attributes defines a collection of sub-attributes as well. A collection of 27 sub-attributes derived from the super-attributes are defined.
Taking into consideration all of the attributes and sub-attributes, a consideration on the quality of the Software of a particular project can be performed.
\item{CMMI}~\cite{CMMI00}.
Code Maturity Model Integration (CMMI) is applied more to the process of Software production rather than the Software itself. Defined in Carnegie Mellon University, this model claims that the modle can be used to guide process improvement across a project, division, or an entire organization.
It basically defines a set of levels that allow to identify the state of the development process up to day. The levels defined are as follow, taking into account that the higher the level is, the more quality the development process of the project has:
\end{itemize}

\begin{itemize}\itemsep0pt
\item{\textbf{Level 1. Initial.}} Processes are unpredictible and unmeasurable, and no reactive.
\item{\textbf{Level 2. Managed.}} Processes are characterized for projects, and often reactive.
\item{\textbf{Level 3. Defined.}} Processes are characterized for the organization and proactive. 
\item{\textbf{Level 4. Quantitatively Managed.}} Development Processes are Measured and Under Control.
\item{\textbf{Level 5. Optimizing.}} Focus on Process Improvement.
\end{itemize}
Both previously defined models, although being complete in terms of quality of the Software and its development process respectiveley, do not take into consideration additional aspects which are considered important only in the case of Open Source Software Projects. Examples of factors not beeing taken into consideration are, e.g.:
\begin{itemize}\itemsep0pt
\item{Community commitment}
\item{Community activity}
\item{What kind of licensing is used? (Copyleft/Permissive)}
\end{itemize}
Fortunately, there have been several approaches to define Quality Models which are more appropriate to be applied to an Open Source Project, and, which indeed, address previous factors, as well as other different ones that are also important to measure particular Quality factors related to this kind of projects. Next section defines some of the most commonly used models.

\subsection{Open Source Software Project Models}

As previously defined, some Open Source Software Project Quality Models have been defined. There are two basic kind of models, taking into account the complexity of its implementation:

\begin{itemize}\itemsep0pt
\item{\textbf{Light-weight}}: This kind of Quality Models are easy to accomplish. Examples of this kind of Quality Models are OpenBRR and QSoS:
\begin{itemize}\itemsep0pt
\item{\textbf{OpenBRR}}~\cite{OPENBRR00}.
Open Business Readiness Rating Quality model defines a Spreadsheet with a set of super-attributes. Each of the super-attributes (named Cathegories in the model). Proposed cathegories by the model are:
\begin{enumerate}\itemsep0pt
\item{\textbf{Functionality}}
\item{\textbf{Usability}}
\item{\textbf{Quality}}
\item{\textbf{Security}}
\item{\textbf{Performance}}
\item{\textbf{Scalability}}
\item{\textbf{Architecture}}
\item{\textbf{Support}}
\item{\textbf{Documentation}}
\item{\textbf{Adoption}}
\item{\textbf{Community}}
\item{\textbf{Professionalism}}
\end{enumerate}
Each of the Cathegories define a set of subcathegories (Metrics) with a description of the metric itself and the specification of the scores that apply to that particular metric. The user of the spreadsheet can assign different weights to both the cathegory and the subcathegories, in order to achieve a final score for the Open Source Project under study.\\
\\
This model, although beeing very improvable, has the merit of being the most simple one among the ones studied. For this reason, our Quality Model will be derived from an even more simple version of this model.
\item{\textbf{QSOS}}~\cite{QSOS00}. Qualification and Selection of Opensource Software is a Quality Model, licensed under GNU Free Documentation License.\\
\\
The quality model defines what is named as the "QSOS Manifesto", which establishes a list of statements for the objectives that this Quality Model tries to define, that can be summarized in:
\begin{itemize}\itemsep0pt
\item{Analyzing needs and limitations in software adoption}
\item{Evaluating functional and technical requirements}
\item{Formalising a methodology}
\item{Results reusing}
\item{Providing a free method}
\end{itemize}
Based on this manifesto, QSOS defines an iterative process that consist of four independent steps:

\begin{itemize}\itemsep0pt
\item{\textbf{Definition}}. Define a frame of references, with software families, types of licenses, types of communities, etc.
\item{\textbf{Evaluation}}. An Evaluation sheet is defined to evaluate the functional coverage and the risks that are to be considered from both user and service provider perspectives.
\item{\textbf{Qualification}}. This step define filters that take into account needs and limitations on the 
specific context of the project.
\item{\textbf{Selection}}. Identify software meeting the needs and/or requirements. Compare sofware and target selection.
\end{itemize}
To summarize, this model, despite the fact that is a light-weight model, is, somehow, a more difficult model to implement compared to OpenBRR. Apart from that, OpenBRR, having the possibility to assign different weights makes OpenBRR a more flexible model, more malleable to the necessities and priorities of a particular role or a particular company.
\end{itemize}
\item{\textbf{Heavy-weight}}: This kind of Quality Models are complex and not easily implementable. A good example of this kind of project is QualOSS.
\begin{itemize}\itemsep0pt
\item{\textbf{QualOSS}}~\cite{QUALOSS00}: Quality of Open Source Software. Started on 2006 and funded mainly by the Eurpoean Union, this project aimed to fill the gap in the state of the art of the Quality Models for Open Source Project Evaluation.\\
\\
It is considered a \textbf{heavy-weight} Quality Model, due to the progress and change of methodology that supposed compared to the already existing Quality Models, described above.\\
\\
One of its first goals consisted of semi-full automation of the analysis of the projects and metrics obtaining, by retrieving them using tools such as FLOSSMetrics~\cite{FLOSSM00}, together with several scripts provided for optimizing this purpose.\\
\\
As this document will not use or even inspire on QualOSS, not very deep information will be provided. However, last but not least, methodology used by this Quality Model is exposed below:
\begin{itemize}\itemsep0pt
\item{\textbf{Initial Steps}}: Consisted of interviews with companies and identification of priorities for them when selecting an Open Source Project. One of the main priorities identified were the Community, and concepts such as \textbf{Community Side}.
\item{\textbf{Basic Quality Model}}: The Methodology followed a GQM (Goal - Question - Metric) basis, where each goal  is divided into several questions, and several metrics are defined for each question.
\item{\textbf{Community Side}}: The main quality attributes identified for the community side were \textbf{Size and Regeneration Adequacy}, on the one hand, as well as \textbf{Interactivity and Workload Adequacy} on the other hand. 
\item{\textbf{Metrics}}: The metrics retrieved should be as objective as possible. One of more metrics are matched with a given question, and always Metrics were result of an average among some data. 
\end{itemize}

\end{itemize}
\end{itemize}

\subsection{Details of the Selected Quality Model}
However, a particular Quality Model is not mandatory to be applied "AS IS". Some variations, limitations, trims, extensions or further considerations can be performed, according to the requirements and priorities defined for a particular Open Source Project.\\
\\
This document does not pretend to be an extensive report or investigation on Quality, but rather an explanation on what a definition of a simple Quality Model for a particular type of Open Source Projects, in this case, related to an incipient and very active technology as Cloud Computing is, and how a particular project scores to that model.\\
\\
For previous reason, in this case, a very simple Quality Model has been developed, taking some of the attributes of OpenBRR on the one hand, and on the other hand implementing and extending other attributes that have been considered to be important for this kind of Cloud Computing Open Source Projects.

\subsubsection{Quality Model Description}
The model is inspired on OpenBRR, but with a set of Cathegories and metrics which differ from the original model. Apart from that, some concepts from ISO 9126~\cite{ISO00, ISO01} have been taken into account.\\
\\
The set of Cathegories agreed for the Quality Model is described below:
\begin{itemize}\itemsep0pt
\item{\textbf{Efficiency}}
\item{\textbf{Documentation}}
\item{\textbf{Functionality}}
\item{\textbf{Professional Support}}
\item{\textbf{Community}}
\end{itemize}

Besides this, each of the cathegories, have a set of questions, with answers that are, somehow, measurable. Apart from that, there are several scores applicable, depending on the metrics obtained. Next tables define, for each cathegory, the metrics and scores applicable.

\begin{table}[H]
  \begin{center}
    \begin{tabular}{ | p{3cm} | p{5cm} | p{3cm} | l | }
    \hline
    Metric & Description & Score Specification & Score \\
    \hline
    Billing System & Does The Cloud System provide a Billing System for User Accounting? & Yes, fully supported & 5 \\ \cline{3-3} \cline{4-4} 
    & & Yes, partially supported & 3 \\ \cline{3-3}\cline{4-4}
    & & No & 1 \\ 
    \hline
    Multi-Platform Support & Does The Cloud System work on top of different Operating Systems?? & Yes, more than two & 5 \\ \cline{3-3} \cline{4-4} 
    & & Yes, two & 3 \\ \cline{3-3}\cline{4-4}
    & & No & 1 \\
    \hline
    Administration Configuration System & Does the Cloud System provide a System (Web preferably) to help on Administration Tasks? & Yes, a web framework & 5 \\ \cline{3-3} \cline{4-4} 
    & & Yes, not web-based & 3 \\ \cline{3-3}\cline{4-4}
    & & No & 1 \\
    \hline
    i18n & Does The Cloud System provide multi-language support & Yes, more than 5 languages & 5 \\ \cline{3-3} \cline{4-4} 
    & & Yes, from 1 to 5 languages & 3 \\ \cline{3-3}\cline{4-4}
    & & No & 1 \\
    \hline
    Quota Management & Does The Cloud System provide a system for quota management & Yes, for computing, storage and networking & 5 \\ \cline{3-3} \cline{4-4} 
    & & Yes, but not for all functionalities & 3 \\ \cline{3-3}\cline{4-4}
    & & No & 1 \\
    \hline

    \end{tabular}
    \caption{Functionality}
    \label{tab:functionality}
  \end{center}
\end{table}

\begin{table}[H]
  \begin{center}
    \begin{tabular}{ | p{3cm} | p{5cm} | p{3cm} | l | }
    \hline
    Metric & Description & Score Specification & Score \\
    \hline
    Performance or Benchmark Tests Available & This measures if there was any performance testing done and benchmarks published â€” typically in comparison to other equivalent solutions & Yes, with good results & 5 \\ \cline{3-3} \cline{4-4} 
    & & Yes & 3 \\ \cline{3-3}\cline{4-4}
    & & No & 1 \\ 
    \hline
    Performance Tuning and Configuration & Is there documentation or tool to help fine-tune the component for performance? & Yes, extensive & 5 \\ \cline{3-3} \cline{4-4} 
    & & Yes, some & 3 \\ \cline{3-3}\cline{4-4}
    & & No & 1 \\ 
    \hline
    \end{tabular}
    \caption{Efficiency}
    \label{tab:efficiency}
  \end{center}
\end{table}

\begin{table}[H]
  \begin{center}
    \begin{tabular}{ | p{3cm} | p{5cm} | p{3cm} | l | }
    \hline
    Metric & Description & Score Specification & Score \\
    \hline
    Company Support & Which is the amount of companies providing support ? & More than one & 5 \\ \cline{3-3} \cline{4-4} 
    & & Just one & 3 \\ \cline{3-3}\cline{4-4}
    & & No one & 1 \\ 
    \hline
    \end{tabular}
    \caption{Support}
    \label{tab:support}
  \end{center}
\end{table}

\begin{table}[H]
  \begin{center}
    \begin{tabular}{ | p{3cm} | p{5cm} | p{3cm} | l | }
    \hline
    Metric & Description & Score Specification & Score \\
    \hline
    Documentation Update & When was the last time that documentation was updated ? & Last week & 5 \\ \cline{3-3} \cline{4-4} 
    & & Last Month & 4 \\ \cline{3-3}\cline{4-4}
    & & Last Three Months & 3 \\ \cline{3-3}\cline{4-4}
    & & Last Year & 2 \\ \cline{3-3}\cline{4-4}
    & & More than one year ago & 1 \\ 
    \hline
    Number of contributors to documentation & Amount of people who contributed to documentation last year & Ten or more people & 5 \\ \cline{3-3} \cline{4-4} 
    & & Five to ten people & 4 \\ \cline{3-3}\cline{4-4}
    & & Two to Five people & 3 \\ \cline{3-3}\cline{4-4}
    & & One person & 2 \\ \cline{3-3}\cline{4-4}
    & & No person & 1 \\ 
    \hline
    \end{tabular}
    \caption{Documentation}
    \label{tab:documentation}
  \end{center}
\end{table}

\begin{table}[H]
  \begin{center}
    \begin{tabular}{ | p{3cm} | p{5cm} | p{3cm} | l | }
    \hline
    Metric & Description & Score Specification & Score \\
    \hline
    Mean commits & Which was the mean number of commits per developer last month? & 20 or more commits / developer & 5 \\ \cline{3-3} \cline{4-4}
    & & 10 to 20 commits / developer & 4 \\ \cline{3-3}\cline{4-4}
    & & 5 to 10 commits / developer & 3 \\ \cline{3-3}\cline{4-4}
    & & 1 to 5 commits / developer & 2 \\ \cline{3-3}\cline{4-4}
    & & \textless 1 commit / developer & 1 \\ 
    \hline
    File Territoriality & Percentage of files of the total modified by a unique developer & \textless 5\% & 5 \\ \cline{3-3} \cline{4-4}
    & & 5\%-10\%  & 4 \\ \cline{3-3}\cline{4-4}
    & & 10\%-20\% & 3 \\ \cline{3-3}\cline{4-4}
    & & 20\%-50\% & 2 \\ \cline{3-3}\cline{4-4}
    & & \textgreater 50\% & 1 \\ 
    \hline
    Community Growth & \% of committers number increase/decrease in the last year, calculated as percent difference in the amount of people who commited changes on 2012 compared to 2013 & \textgreater50\% & 5 \\ \cline{3-3} \cline{4-4}
    & & 25\% to 50\% & 4 \\ \cline{3-3}\cline{4-4}
    & & 0\% to 25\%  & 3 \\ \cline{3-3}\cline{4-4}
    & & 0\% to -25\% & 2 \\ \cline{3-3}\cline{4-4}
    & & \textless-25\%       & 1 \\ 
    \hline
    \end{tabular}
    \caption{Community}
    \label{tab:community}
  \end{center}
\end{table}
The Quality Model Spreadsheet previously described can be downloaded at next repository:\\
\\
\url{https://github.com/MSWL-PROJ-EV-2013-2014/projev.git}\\
\\
In particular, the Quality Model Spreadsheet can be downloaded on path "spreadsheet/BRR\_ProjEval\_2013.ods", or directly through next path:\\
\\
\url{https://github.com/MSWL-PROJ-EV-2013-2014/projev/blob/master/spreadsheet/BRR_ProjEval_2013.ods}
\subsubsection{Weights}

\subsubsection{Tools for Metrics Retrieval}

\subsubsection{Data Sources}


\section{Analysis} \label{sec:analysis}

\section{Results} \label{sec:results}

\section{Conclussion} \label{sec:conclussion}

\section{Bibliography and References} \label{sec:bibliography}
\bibliographystyle{unsrt}
\bibliography{mybib}{}
\end{document}
